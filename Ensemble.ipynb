{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11315ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from modeling_distill import BertForDistillSequenceClassification\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58094524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(model):\n",
    "# model = \"mrpc/baseline_base_seed0_BS64_lr9e-5_epoch3/predict_results_mrpc.txt\"\n",
    "\n",
    "    model_file = open(model,'r')\n",
    "    model_labels = [line.split(\"\\t\")[-1].strip() for line in model_file][1:]\n",
    "    model_labels = [1 if t==\"equivalent\" else 0 for t in model_labels]\n",
    "    return model_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb1ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(l):\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(len(l[0])):\n",
    "        vot = 0\n",
    "        for j in range(len(l)):\n",
    "            vot += l[j][i]\n",
    "        if vot > 2:\n",
    "            ret.append(1)\n",
    "        else:\n",
    "            ret.append(0)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f67abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for m in [1,2,3,4,5]:\n",
    "    l.append(get_labels(\"mrpc/baseline_large_seed{}_BS32_lr3e-5_epoch3/predict_results_mrpc.txt\".format(m)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cae71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_ret = ensemble(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d5b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mrpc/baseline_large_ensemble/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ad5a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"mrpc/baseline_large_ensemble/predict_results_mrpc.txt\",'w')\n",
    "f.write(\"index\\tprediction\\n\")\n",
    "for i, x in enumerate(ens_ret):\n",
    "    if x == 1:\n",
    "        f.write(str(i) + \"\\tequivalent\\n\")\n",
    "    else:\n",
    "        f.write(str(i) + \"\\tnot_equivalent\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ca183e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task = \"mrpc\"\n",
    "old_model = \"mrpc/base_seed0_BS32_lr3e-5_epoch4\"\n",
    "# old_model = \"qqp/baseline_base_seed0_BS64_lr9e-5_epoch5\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    old_model,\n",
    "    num_labels=2,\n",
    "    finetuning_task=task\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    old_model,\n",
    ")\n",
    "tea_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    old_model,\n",
    "    config=config,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=tea_model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a19c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c60bd10af6409e8a59a89c0b33f6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ea916b755ec3b506.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-12ded0ffec826fdd.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3f0b6fbcfadb607d.arrow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "\n",
    "# Preprocessing the raw_datasets\n",
    "\n",
    "sentence1_key, sentence2_key = \"sentence1\", \"sentence2\"\n",
    "# sentence1_key, sentence2_key = \"question1\", \"question2\"\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "#     print(examples)\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, padding=True, max_length=128, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "#     if label_to_id is not None and \"label\" in examples:\n",
    "#         result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", task)\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "\n",
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "\n",
    "predict_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "label_list = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01afd651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "old_output = trainer.predict(raw_datasets[\"validation\"], metric_key_prefix=\"predict\")\n",
    "old_prob = softmax(old_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c2fe1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"gated_v4/mrpc_new/gatedinit_large_seed3_BS12_lr3e-6_initepoch3\",\n",
      "  \"architectures\": [\n",
      "    \"BertForGatedSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": \"mrpc\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": 0,\n",
      "    \"1\": 1\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"0\": 0,\n",
      "    \"1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"train_gate\": true,\n",
      "  \"transformers_version\": \"4.11.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "Didn't find file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/added_tokens.json. We won't load it.\n",
      "loading file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/vocab.txt\n",
      "loading file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/tokenizer.json\n",
      "loading file None\n",
      "loading file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/special_tokens_map.json\n",
      "loading file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/tokenizer_config.json\n",
      "loading weights file gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForGatedSequenceClassification.\n",
      "\n",
      "All the weights of BertForGatedSequenceClassification were initialized from the model checkpoint at gated_v4/mrpc_new/gatedfinal_large_seed3_BS12_lr3e-6_epoch3_3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForGatedSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from modeling_BFSC_2l import BertForGatedSequenceClassification\n",
    "\n",
    "seed = 3\n",
    "# new_model = \"qqp/baseline_large_seed{}_BS32_lr3e-5_epoch5\".format(seed)\n",
    "new_model = \"gated_v4/mrpc_new/gatedfinal_large_seed{}_BS12_lr3e-6_epoch3_3\".format(seed)\n",
    "config = AutoConfig.from_pretrained(\n",
    "    new_model,\n",
    "    num_labels=2,\n",
    "    finetuning_task=task,\n",
    "#     output_hidden_states=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    new_model,\n",
    ")\n",
    "model = BertForGatedSequenceClassification.from_pretrained(\n",
    "    new_model,\n",
    "    teacher_model=tea_model,\n",
    "    config=config,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "output = trainer.predict(raw_datasets[\"validation\"], metric_key_prefix=\"eval\")\n",
    "new_prob = softmax(output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122659f7",
   "metadata": {},
   "source": [
    "## Ensemble Old & New:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f50a4364",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'mrpc/old_new_base_seed3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-20aaf9dbf06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mrpc/old_new_base_seed{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'mrpc/old_new_base_seed3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.mkdir(\"mrpc/old_new_base_seed{}\".format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae56c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = np.argmax(new_prob + old_prob, axis=1)\n",
    "with open(\"mrpc/old_new_base_seed{}/predict_results_mrpc.txt\".format(seed), \"w\") as writer:\n",
    "#     logger.info(f\"***** Predict results {task} *****\")\n",
    "    writer.write(\"index\\tprediction\\n\")\n",
    "    for index, item in enumerate(predictions):\n",
    "#         if is_regression:\n",
    "#             writer.write(f\"{index}\\t{item:3.3f}\\n\")\n",
    "#         else:\n",
    "        item = label_list[item]\n",
    "        writer.write(f\"{index}\\t{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22696f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, IterableDataset, RandomSampler, SequentialSampler\n",
    "from transformers.data.data_collator import default_data_collator, DataCollatorWithPadding\n",
    "test_dataloader = DataLoader(\n",
    "    raw_datasets[\"validation\"],\n",
    "    collate_fn=default_data_collator,\n",
    "    batch_size=8,\n",
    "#     collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "#                 num_workers=self.args.dataloader_num_workers,\n",
    "#                 pin_memory=self.args.dataloader_pin_memory,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83151a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "outputs = []\n",
    "model.eval()\n",
    "labels = []\n",
    "for x in test_dataloader:\n",
    "    y = {\n",
    "        \"input_ids\": x[\"input_ids\"].to(\"cuda\"),\n",
    "        \"attention_mask\": x[\"attention_mask\"].to(\"cuda\"),\n",
    "        \"token_type_ids\": x[\"token_type_ids\"].to(\"cuda\"),\n",
    "        \"labels\": x[\"labels\"].to(\"cuda\"),\n",
    "        }\n",
    "    labels.append(x[\"labels\"])\n",
    "    with torch.no_grad():\n",
    "        output = model(\n",
    "            input_ids=y[\"input_ids\"],\n",
    "            attention_mask=y[\"attention_mask\"],\n",
    "            token_type_ids=y[\"token_type_ids\"],\n",
    "            labels=y[\"labels\"],\n",
    "            output_hidden_states=True,\n",
    "            return_dict=False\n",
    "        )\n",
    "\n",
    "#     print(output[3])\n",
    "#     input()\n",
    "    del y\n",
    "    torch.cuda.empty_cache()\n",
    "    outputs.append(output[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e57579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates = []\n",
    "for out in outputs:\n",
    "    gates += [x[0] for x in out.tolist()]\n",
    "len(gates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd51a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for l in labels:\n",
    "    ls += [x for x in l.tolist()]\n",
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed01a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_labels = []\n",
    "for p in old_prob:\n",
    "#     print(p)\n",
    "    if p[0] >= p[1]:\n",
    "        old_labels.append(0)\n",
    "    else:\n",
    "         old_labels.append(1)\n",
    "# old_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bd11312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_output\n",
    "# output.predictions\n",
    "# (n -  (1-g) * o ) / g = on +\n",
    "gates = np.array(gates)\n",
    "old_l = np.transpose(old_output.predictions)\n",
    "ot = (1 - gates) * old_l\n",
    "m = np.transpose(output.predictions) - ot\n",
    "new_logits = m / gates\n",
    "new_logits = np.transpose(new_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781cea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_labels == orig_new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd104f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_new_labels = []\n",
    "for p in new_logits:\n",
    "#     print(p)\n",
    "    if p[0] >= p[1]:\n",
    "        orig_new_labels.append(0)\n",
    "    else:\n",
    "        orig_new_labels.append(1)\n",
    "# orig_new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc02937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForGatedSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = trainer.predict(raw_datasets[\"validation\"], metric_key_prefix=\"eval\")\n",
    "new_prob = softmax(output.predictions, axis=1)\n",
    "new_labels = []\n",
    "for p in new_prob:\n",
    "#     print(p)\n",
    "    if p[0] >= p[1]:\n",
    "        new_labels.append(0)\n",
    "    else:\n",
    "         new_labels.append(1)\n",
    "# new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88b81875",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(ls)\n",
    "pf = []\n",
    "nf = []\n",
    "pnf = []\n",
    "nnf = []\n",
    "fixed_nf = []\n",
    "fixed_f = []\n",
    "for i, l in enumerate(ls):\n",
    "    if l == orig_new_labels[i]:\n",
    "        if l == old_labels[i]:\n",
    "            pnf.append(i)\n",
    "        else:\n",
    "            pf.append(i)\n",
    "    else:\n",
    "        if new_labels[i] == l:\n",
    "            fixed_f.append(i)\n",
    "        if l == old_labels[i]:\n",
    "            nf.append(i)\n",
    "            if new_labels[i] == l:\n",
    "                fixed_nf.append(i)\n",
    "        else:\n",
    "            nnf.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00ac1995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[338]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "240fe070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts in Dev set')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# bins = range(0.4, 0.7, 0.05)\n",
    "bins = np.linspace(0.45, 0.7, 80)\n",
    "# matplotlib histogram\n",
    "gates_pf = [gates[x] for x in pf]\n",
    "gates_nf = [gates[x] for x in nf]\n",
    "gates_pnf = [gates[x] for x in pnf]\n",
    "gates_nnf = [gates[x] for x in nnf]\n",
    "\n",
    "\n",
    "plt.hist(gates_pf, color = 'blue', edgecolor = 'black',bins=bins, alpha=0.8, label=\"PF\")\n",
    "plt.hist(gates_nf, color = 'yellow', edgecolor = 'black',bins=bins, alpha=0.8, label=\"NF\")\n",
    "# plt.hist(gates_pnf, color = 'green', edgecolor = 'black', bins=bins)\n",
    "plt.hist(gates_nnf, color = 'red', edgecolor = 'black',bins=bins, alpha=0.8, label=\"NNF\")\n",
    "\n",
    "# seaborn histogram\n",
    "# sns.distplot(gates, hist=True, kde=False, \n",
    "#              bins=bins, color = 'blue',\n",
    "#              hist_kws={'edgecolor':'black'})\n",
    "# Add labels\n",
    "plt.title('Histogram of Gate value Seed {}'.format(seed))\n",
    "plt.xlabel('gate value')\n",
    "plt.ylabel('Counts in Dev set')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a5a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
